2.1
1)There are nine possible values that can be written in a given square, so the branching factor for the successor function is 9.

2) DFS will be finite on the Sudoku problem - eventually the search problem runs out of numbers to use. The maximum search depth is also r, for the same reason. We only have r spaces to work with, so we can only make r choices.

3) The best-case run time complexity for DFS is r (guesses it correctly on the first try). The worst-case complexity is 9^r (branching factor of 9), because the DFS will have to try all possibilities.

4) The best-case for BFS would be 9^(r-1) + 1 , and the worst-case would be 9^r.
  //solution is either the first item in the row (best case) or last item     
  (worst case)

5) The space complexity for BFS is 9^r, in this case. This would yield a space
complexity of 9^40, or 2^126 in base 2. 2^126 is FAR beyond even the age of the universe, so storing 2^126 bytes is clearly impossible.

6) There are 9 options for each of the originally empty positions, so there are
9^r states available.

7) Part 3 suggests that we consider pick two originally empty positions and swap
them. Another (original) function we could consider using is to pick a single
originally empty function and assign it a random number.

Bonus Question) 
The "above algorithm," which I assume is the one listed in section 3.2.1 of the
homework, does not specify whether we should accept or reject neutral changes.
We implemented both and found that accepting neutral changes led to faster
learning - when we required a strict improvement, simulated annealing often
didn't solve the medium board, and it worked for all ten trials after the
switch.
We suspect it's because it is easier to accept a change that steps away from a
local extremum, though this might be a sudoku-specific effect.


